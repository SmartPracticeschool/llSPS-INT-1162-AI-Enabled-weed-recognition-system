{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add convolution layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Flattening Layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=60, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Hidden Layer\n",
    "model.add(Dense(init=\"uniform\",activation=\"relu\",output_dim=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Output layer\n",
    "model.add(Dense(init=\"uniform\",activation=\"sigmoid\",output_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2800 images belonging to 2 classes.\n",
      "Found 1200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory('C:/Users/pragn/Desktop/cnn dataset/trainset',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                     class_mode = 'binary')\n",
    "x_test = test_datagen.flow_from_directory('C:/Users/pragn/Desktop/cnn dataset/testset',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal crop': 0, 'weed': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "87/87 [==============================] - 15s 177ms/step - loss: 0.5629 - acc: 0.7468 - val_loss: 0.5241 - val_acc: 0.7508\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 14s 159ms/step - loss: 0.4877 - acc: 0.7572 - val_loss: 0.4429 - val_acc: 0.8151\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.4120 - acc: 0.8172 - val_loss: 0.3798 - val_acc: 0.8116\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.3627 - acc: 0.8218 - val_loss: 0.3316 - val_acc: 0.8176\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 0.3376 - acc: 0.8412 - val_loss: 0.3046 - val_acc: 0.8330\n",
      "Epoch 6/30\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.3314 - acc: 0.8427 - val_loss: 0.3017 - val_acc: 0.8399\n",
      "Epoch 7/30\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.3257 - acc: 0.8427 - val_loss: 0.2694 - val_acc: 0.8724\n",
      "Epoch 8/30\n",
      "87/87 [==============================] - 14s 158ms/step - loss: 0.3057 - acc: 0.8560 - val_loss: 0.2714 - val_acc: 0.8587\n",
      "Epoch 9/30\n",
      "87/87 [==============================] - 16s 182ms/step - loss: 0.3145 - acc: 0.8549 - val_loss: 0.3192 - val_acc: 0.8673\n",
      "Epoch 10/30\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.3057 - acc: 0.8585 - val_loss: 0.2551 - val_acc: 0.8836\n",
      "Epoch 11/30\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.2942 - acc: 0.8660 - val_loss: 0.2501 - val_acc: 0.8776\n",
      "Epoch 12/30\n",
      "87/87 [==============================] - 15s 169ms/step - loss: 0.2915 - acc: 0.8653 - val_loss: 0.2669 - val_acc: 0.8656\n",
      "Epoch 13/30\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 0.2890 - acc: 0.8728 - val_loss: 0.2343 - val_acc: 0.8981\n",
      "Epoch 14/30\n",
      "87/87 [==============================] - 14s 162ms/step - loss: 0.2891 - acc: 0.8732 - val_loss: 0.2741 - val_acc: 0.8724\n",
      "Epoch 15/30\n",
      "87/87 [==============================] - 16s 178ms/step - loss: 0.2711 - acc: 0.8786 - val_loss: 0.2730 - val_acc: 0.8664\n",
      "Epoch 16/30\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 0.2746 - acc: 0.8800 - val_loss: 0.2340 - val_acc: 0.8861\n",
      "Epoch 17/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.2818 - acc: 0.8754 - val_loss: 0.2459 - val_acc: 0.8836\n",
      "Epoch 18/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.2653 - acc: 0.8764 - val_loss: 0.3846 - val_acc: 0.8108\n",
      "Epoch 19/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.2650 - acc: 0.8847 - val_loss: 0.2610 - val_acc: 0.8699\n",
      "Epoch 20/30\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 0.2665 - acc: 0.8786 - val_loss: 0.5197 - val_acc: 0.7962\n",
      "Epoch 21/30\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.2601 - acc: 0.8818 - val_loss: 0.3301 - val_acc: 0.8365\n",
      "Epoch 22/30\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 0.2592 - acc: 0.8847 - val_loss: 0.2201 - val_acc: 0.8930\n",
      "Epoch 23/30\n",
      "87/87 [==============================] - 14s 157ms/step - loss: 0.2521 - acc: 0.8872 - val_loss: 0.2387 - val_acc: 0.8947\n",
      "Epoch 24/30\n",
      "87/87 [==============================] - 15s 167ms/step - loss: 0.2692 - acc: 0.8836 - val_loss: 0.2353 - val_acc: 0.9050\n",
      "Epoch 25/30\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.2456 - acc: 0.8854 - val_loss: 0.2181 - val_acc: 0.89472s - loss: 0.24\n",
      "Epoch 26/30\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 0.2574 - acc: 0.8861 - val_loss: 0.2089 - val_acc: 0.8964\n",
      "Epoch 27/30\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 0.2474 - acc: 0.8919 - val_loss: 0.3122 - val_acc: 0.8579\n",
      "Epoch 28/30\n",
      "87/87 [==============================] - 16s 183ms/step - loss: 0.2356 - acc: 0.8958 - val_loss: 0.2720 - val_acc: 0.8664\n",
      "Epoch 29/30\n",
      "87/87 [==============================] - 14s 155ms/step - loss: 0.2515 - acc: 0.8886 - val_loss: 0.2196 - val_acc: 0.8973\n",
      "Epoch 30/30\n",
      "87/87 [==============================] - 14s 166ms/step - loss: 0.2558 - acc: 0.8922 - val_loss: 0.2832 - val_acc: 0.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ccdd306d88>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,\n",
    "                         steps_per_epoch = 2800//32,\n",
    "                         epochs = 30,\n",
    "                         validation_data = x_test,\n",
    "                         validation_steps = 1200//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"intmodel.h5\")\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = image.load_img('C:/Users/pragn/Desktop/cnn dataset/testset/weed/grass/751.png',target_size=(64,64))\n",
    "img_pred=image.img_to_array(img_pred)\n",
    "img_pred=np.expand_dims(img_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "weed\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(img_pred)\n",
    "print(result)\n",
    "if result[0][0]==1:\n",
    "    prediction=\"weed\"\n",
    "else:\n",
    "    prediction=\"crop\"\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
